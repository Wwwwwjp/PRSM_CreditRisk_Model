{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f9c84555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LassoCV, LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1a1569b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('credit_installment2_id5.csv')\n",
    "df_eval = pd.read_csv('credit_installment2_evaluation_data.csv')\n",
    "#yy = df_eval['PRSM']\n",
    "#df_eval = df_eval.drop(['PRSM'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9f47ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocesses a dataset by performing feature engineering, \n",
    "    transformation, encoding, and scaling.\n",
    "    \"\"\"\n",
    "    # Calculate Delinquent Credit Ratio\n",
    "    df[\"Delinquent_Credit_Ratio\"] = df[\"Num_Delinquent\"] / df[\"Num_CreditLines\"]\n",
    "    \n",
    "    # Cap 'Months' feature at 30\n",
    "    df['Months'] = df['Months'].apply(lambda x: x if x < 30 else 30)\n",
    "    \n",
    "    # Create FICO bin labels\n",
    "    bins = [300, 580, 670, 740, 800, float('inf')]\n",
    "    labels = ['Poor', 'Fair', 'Good', 'Very Good', 'Excellent']\n",
    "    df['FICO_bin'] = pd.cut(df['FICO'], bins=bins, labels=labels, right=False)\n",
    "    \n",
    "    # Extract first two digits from NAICS code\n",
    "    df['NAICS_2digit'] = df['NAICS'].astype(str).str.zfill(6).str[:2]\n",
    "    \n",
    "    # Apply log transformation to skewed numerical features\n",
    "    df['Stress'] = np.log1p(df['Stress'])\n",
    "    df['Volume'] = np.log1p(df['Volume'])\n",
    "    df['TotalAmtOwed'] = np.log1p(df['TotalAmtOwed'])\n",
    "    \n",
    "    # One-hot encode categorical features\n",
    "    for col in ['FICO_bin', 'CorpStructure', 'NAICS_2digit']:\n",
    "        df = pd.get_dummies(df, columns=[col], drop_first=True)\n",
    "    \n",
    "    # Drop original categorical columns\n",
    "    df = df.drop(['FICO', 'NAICS'], axis=1)\n",
    "    \n",
    "    # Standardize numerical features\n",
    "    cols_to_scale = [\"Months\", \"Volume\", \"TotalAmtOwed\", \"Stress\"]\n",
    "    scaler = StandardScaler()\n",
    "    df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n",
    "    df[cols_to_scale] = df[cols_to_scale] * 0.25 + 0.5\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d5d379fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_values = {\n",
    "    'FICO': 700,\n",
    "    'TotalAmtOwed': 200000,\n",
    "    'Volume': 140000,\n",
    "    'Stress': 0.2,\n",
    "    'Num_Delinquent': 4,\n",
    "    'Num_CreditLines': 10,\n",
    "    'WomanOwned': 1,\n",
    "    'CorpStructure': 'LLC',\n",
    "    'NAICS': 445291,\n",
    "    'Months':18,\n",
    "    'PRSM': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "57c71008",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extended = pd.concat([df_train, pd.DataFrame([baseline_values])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e63159bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = preprocess_data(df_train)\n",
    "df_extended = preprocess_data(df_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3ba1b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = df_extended.tail(1).drop(columns=['PRSM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4ee0bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['PRSM']\n",
    "X = df_train.drop(columns=['PRSM'])\n",
    "\n",
    "X = X.drop(['Num_Delinquent', 'Num_CreditLines', 'Volume'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "05084a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm = sm.add_constant(X) \n",
    "ols_model = sm.OLS(y, X_train_sm).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "04555d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df['const'] = 1\n",
    "baseline_df = baseline_df.drop(['Num_Delinquent', 'Num_CreditLines', 'Volume'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c3e304ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Borrower Predicted PRSM: 0.9192\n",
      "95% Prediction Interval: (0.5997, 1.2386)\n"
     ]
    }
   ],
   "source": [
    "predictions = ols_model.get_prediction(baseline_df)\n",
    "summary_frame = predictions.summary_frame(alpha=0.05)  # 95% 置信区间\n",
    "\n",
    "# 提取预测值和置信区间\n",
    "predicted_prsm = summary_frame[\"mean\"][0]\n",
    "lower_bound = summary_frame[\"obs_ci_lower\"][0]  # 观测置信区间下界\n",
    "upper_bound = summary_frame[\"obs_ci_upper\"][0]  # 观测置信区间上界\n",
    "\n",
    "# 输出结果\n",
    "print(f\"Baseline Borrower Predicted PRSM: {predicted_prsm:.4f}\")\n",
    "print(f\"95% Prediction Interval: ({lower_bound:.4f}, {upper_bound:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "36fda73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = preprocess_data(df_eval)\n",
    "df_eval = sm.add_constant(df_eval)\n",
    "df_eval = df_eval.drop(['Num_Delinquent', 'Num_CreditLines', 'Volume'], axis=1)\n",
    "predictions = ols_model.get_prediction(df_eval)\n",
    "pred_summary = predictions.summary_frame(alpha=0.05)  \n",
    "\n",
    "output_df = pred_summary[['mean', 'obs_ci_lower', 'obs_ci_upper']]\n",
    "output_df.columns = ['Point_Prediction', 'Lower_Bound', 'Upper_Bound']\n",
    "\n",
    "output_df.to_csv(\"predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b460e4",
   "metadata": {},
   "source": [
    "yy = yy.squeeze()  # 转换为 Series 以匹配 output_df 结构\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(yy, output_df[\"Point_Prediction\"]))\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "covered = ((yy >= output_df[\"Lower_Bound\"]) & (yy <= output_df[\"Upper_Bound\"])).mean()\n",
    "print(f\"95% Prediction Interval Coverage: {covered:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e532f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
